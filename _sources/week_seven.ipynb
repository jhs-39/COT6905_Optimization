{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac2d809",
   "metadata": {},
   "source": [
    "# Week 7: Symmetric and Complex Matrices\n",
    "\n",
    "## Lecture 25: Symmetric matrices and positive definiteness\n",
    "\n",
    "<iframe width=\"560\" height=\"315\"\n",
    "    src=\"https://www.youtube.com/embed/UCc9q_cAhho\"\n",
    "    frameborder=\"0\"\n",
    "    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n",
    "    allowfullscreen>\n",
    "</iframe>\n",
    "\n",
    "Symmetric matrices are the most important class in applications: they have **real eigenvalues**, **orthogonal eigenvectors**, and lead to the beautiful **spectral theorem**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Symmetric Matrix\n",
    "\n",
    "\\[\n",
    "\\boxed{A = A^T}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Key Properties\n",
    "\n",
    "For real symmetric $A$:\n",
    "\n",
    "- All eigenvalues $\\lambda_i$ are **real**.\n",
    "- Eigenvectors belonging to different eigenvalues are **orthogonal**.\n",
    "- We can choose a full set of **orthonormal eigenvectors** $\\{q_1, \\dots, q_n\\}$.\n",
    "\n",
    "Let $Q = [q_1 \\cdots q_n]$ (orthogonal matrix, $Q^T Q = I$).\n",
    "\n",
    "Then:\n",
    "\n",
    "\\[\n",
    "\\boxed{A = Q \\Lambda Q^T}, \\quad \\Lambda = \\operatorname{diag}(\\lambda_1, \\dots, \\lambda_n)\n",
    "\\]\n",
    "\n",
    "This is the **spectral theorem** (or **principal axis theorem**).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Why Real Eigenvalues?\n",
    "\n",
    "Let $Ax = \\lambda x$ ($x \\neq 0$).\n",
    "\n",
    "Take complex conjugate:\n",
    "\n",
    "\\[\n",
    "A \\bar{x} = \\bar{\\lambda} \\bar{x}\n",
    "\\]\n",
    "\n",
    "Multiply first equation by $\\bar{x}^T$ (left):\n",
    "\n",
    "\\[\n",
    "\\bar{x}^T A x = \\lambda \\bar{x}^T x\n",
    "\\]\n",
    "\n",
    "Transpose:\n",
    "\n",
    "\\[\n",
    "x^T A^T \\bar{x} = \\bar{\\lambda} x^T \\bar{x}\n",
    "\\]\n",
    "\n",
    "Since $A = A^T$:\n",
    "\n",
    "\\[\n",
    "x^T A \\bar{x} = \\bar{\\lambda} x^T \\bar{x}\n",
    "\\]\n",
    "\n",
    "But $x^T A \\bar{x} = \\bar{x}^T A x = \\lambda \\bar{x}^T x$, so\n",
    "\n",
    "\\[\n",
    "\\lambda \\bar{x}^T x = \\bar{\\lambda} \\bar{x}^T x \\quad \\Rightarrow \\quad \\lambda = \\bar{\\lambda}\n",
    "\\]\n",
    "\n",
    "$\\lambda$ is real!\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Rank-1 Expansion\n",
    "\n",
    "\\[\n",
    "A = \\sum_{i=1}^n \\lambda_i q_i q_i^T\n",
    "\\]\n",
    "\n",
    "Each term $\\lambda_i q_i q_i^T$ is a scaled **projection** onto the direction $q_i$.\n",
    "\n",
    "Symmetric matrices are linear combinations of perpendicular rank-1 projections.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Positive Definite Matrices\n",
    "\n",
    "$A$ (symmetric) is **positive definite** if\n",
    "\n",
    "\\[\n",
    "\\boxed{x^T A x > 0 \\quad \\forall x \\neq 0}\n",
    "\\]\n",
    "\n",
    "**Equivalent conditions**:\n",
    "\n",
    "- All eigenvalues $\\lambda_i > 0$\n",
    "- All pivots $> 0$ (in elimination)\n",
    "- All leading principal minors $> 0$\n",
    "- $\\det(A) > 0$ and all submatrix determinants positive\n",
    "- Cholesky factorization exists: $A = L L^T$ ($L$ lower triangular)\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Example\n",
    "\n",
    "\\[\n",
    "A = \\begin{pmatrix} 5 & 2 \\\\ 2 & 3 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "Eigenvalues: solve $\\det(A - \\lambda I) = (5-\\lambda)(3-\\lambda) - 4 = \\lambda^2 - 8\\lambda + 11 = 0$\n",
    "\n",
    "\\[\n",
    "\\lambda = \\frac{8 \\pm \\sqrt{64-44}}{2} = 4 \\pm \\sqrt{5} \\quad (\\text{both positive})\n",
    "\\]\n",
    "\n",
    "Quadratic form:\n",
    "\n",
    "\\[\n",
    "x^T A x = 5x_1^2 + 4x_1 x_2 + 3x_2^2 = (x_1 + x_2)^2 + 4x_1^2 + 2x_2^2 > 0 \\quad (x \\neq 0)\n",
    "\\]\n",
    "\n",
    "Positive definite.\n",
    "\n",
    "---\n",
    "\n",
    "### Code: Check Positive Definiteness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5571df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "A = np.array([[5, 2],\n",
    "              [2, 3]], dtype=float)\n",
    "\n",
    "eigvals = np.linalg.eigvals(A)\n",
    "is_pd_eig = np.all(eigvals > 0)\n",
    "\n",
    "# Cholesky (fails if not PD)\n",
    "try:\n",
    "    L = np.linalg.cholesky(A)\n",
    "    cholesky_success = True\n",
    "except np.linalg.LinAlgError:\n",
    "    cholesky_success = False\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "**Matrix** $$ A = \\\\begin{{pmatrix}} 5 & 2 \\\\\\\\ 2 & 3 \\\\end{{pmatrix}} $$\n",
    "\n",
    "**Eigenvalues**: $$ {np.round(eigvals, 4).tolist()} $$\n",
    "\n",
    "Positive definite (eigenvalues)? **{'Yes' if is_pd_eig else 'No'}**\n",
    "\n",
    "Cholesky factorization exists? **{'Yes' if cholesky_success else 'No'}**\n",
    "\n",
    "$$ L = \\\\begin{{pmatrix}} {L[0,0]:.3f} & 0 \\\\\\\\ {L[1,0]:.3f} & {L[1,1]:.3f} \\\\end{{pmatrix}} $$ (if successful)\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89420343",
   "metadata": {},
   "source": [
    "## Lecture 26: Complex matrices; fast fourier transform\n",
    "\n",
    "<iframe width=\"560\" height=\"315\"\n",
    "    src=\"https://www.youtube.com/embed/M0Sa8fLOajA\"\n",
    "    frameborder=\"0\"\n",
    "    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n",
    "    allowfullscreen>\n",
    "</iframe>\n",
    "\n",
    "We extend linear algebra to complex numbers — necessary for the **Fourier transform** and its fast algorithm, the **FFT**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Complex Inner Product\n",
    "\n",
    "For complex vectors $x, y \\in \\mathbb{C}^n$:\n",
    "\n",
    "\\[\n",
    "\\boxed{\\langle y, x \\rangle = y^H x}\n",
    "\\]\n",
    "\n",
    "where $y^H = \\bar{y}^T$ is the **conjugate transpose** (Hermitian transpose).\n",
    "\n",
    "- $\\|x\\|^2 = x^H x = \\sum |x_i|^2 \\geq 0$\n",
    "- Orthogonality: $y^H x = 0$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Hermitian Matrices\n",
    "\n",
    "A complex matrix $A$ is **Hermitian** if\n",
    "\n",
    "\\[\n",
    "\\boxed{A^H = A}\n",
    "\\]\n",
    "\n",
    "Properties (analogous to real symmetric):\n",
    "\n",
    "- Diagonal entries are real.\n",
    "- Eigenvalues are **real**.\n",
    "- Eigenvectors for distinct eigenvalues are orthogonal (w.r.t. complex inner product).\n",
    "- Orthonormal basis of eigenvectors exists: $Q$ with $Q^H Q = I$.\n",
    "\n",
    "Then:\n",
    "\n",
    "\\[\n",
    "\\boxed{A = Q \\Lambda Q^H}, \\quad \\Lambda \\text{ real diagonal}\n",
    "\\]\n",
    "\n",
    "Such $Q$ is called **unitary** ($Q^{-1} = Q^H$).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Example: 2×2 Hermitian\n",
    "\n",
    "\\[\n",
    "A = \\begin{pmatrix} 2 & 3+i \\\\ 3-i & 5 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "$A^H = A$, diagonal real → Hermitian.\n",
    "\n",
    "Eigenvalues real, eigenvectors orthogonal under $y^H x = 0$.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Fourier Matrix\n",
    "\n",
    "The $n \\times n$ **Fourier matrix** $F_n$:\n",
    "\n",
    "\\[\n",
    "(F_n)_{jk} = \\omega^{jk}, \\quad \\omega = e^{2\\pi i / n} = \\cos\\frac{2\\pi}{n} + i \\sin\\frac{2\\pi}{n}\n",
    "\\]\n",
    "\n",
    "(Indices usually $j,k = 0,\\dots,n-1$.)\n",
    "\n",
    "Example $n=4$ ($\\omega = i$):\n",
    "\n",
    "\\[\n",
    "F_4 = \\begin{pmatrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & i & i^2 & i^3 \\\\\n",
    "1 & i^2 & i^4 & i^6 \\\\\n",
    "1 & i^3 & i^6 & i^9\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & i & -1 & -i \\\\\n",
    "1 & -1 & 1 & -1 \\\\\n",
    "1 & -i & -1 & i\n",
    "\\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "Key property: columns are orthogonal under complex inner product.\n",
    "\n",
    "Scaled version is unitary: $F_n^H F_n = n I$.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Fast Fourier Transform (FFT)\n",
    "\n",
    "Direct matrix-vector multiply $F_n x$: $O(n^2)$ operations.\n",
    "\n",
    "**Cooley–Tukey FFT** exploits structure recursively:\n",
    "\n",
    "\\[\n",
    "F_{2m} = P \\begin{pmatrix} I & D \\\\ I & -D \\end{pmatrix} \\begin{pmatrix} F_m & 0 \\\\ 0 & F_m \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "- $D$: diagonal with powers of $\\omega^2$\n",
    "- $P$: permutation (evens first, odds second)\n",
    "\n",
    "Cost recurrence:\n",
    "\n",
    "\\[\n",
    "T(n) = 2 T(n/2) + O(n) \\quad \\Rightarrow \\quad \\boxed{T(n) = O(n \\log n)}\n",
    "\\]\n",
    "\n",
    "Huge speedup: $n=10^6$ → $10^{12}$ vs $\\sim 2 \\times 10^7$ operations.\n",
    "\n",
    "---\n",
    "\n",
    "### Code: Fourier Matrix and FFT Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "n = 8\n",
    "omega = np.exp(2j * np.pi / n)\n",
    "j, k = np.meshgrid(np.arange(n), np.arange(n))\n",
    "F = omega ** (j * k)\n",
    "\n",
    "# Orthonormality check (up to scaling)\n",
    "scaled_F = F / np.sqrt(n)\n",
    "error = np.linalg.norm(scaled_F.conj().T @ scaled_F - np.eye(n))\n",
    "\n",
    "# Compare direct vs np.fft\n",
    "x = np.random.randn(n) + 1j * np.random.randn(n)\n",
    "direct = F @ x\n",
    "fft_result = np.fft.fft(x)\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "**Fourier matrix** $$ F_{{{n}}} $$ (first 4×4 block shown):\n",
    "\n",
    "$$  \\\\begin{{pmatrix}}\n",
    "{np.real(F[:4,:4]).astype(int)} + i\\\\{np.imag(F[:4,:4]).astype(int)}\n",
    "\\\\end{{pmatrix}}  $$\n",
    "\n",
    "Scaled $$ F/\\\\sqrt{{{n}}} $$ is unitary (error $$ \\\\approx {error:.2e} $$)\n",
    "\n",
    "**Direct multiply**: {np.round(direct[:4], 3)}\n",
    "\n",
    "**np.fft.fft**      : {np.round(fft_result[:4], 3)}\n",
    "\n",
    "Match? **{'Yes' if np.allclose(direct, fft_result) else 'No'}**\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353aaedc",
   "metadata": {},
   "source": [
    "## Lecture 27: Positive definite matrices and minima\n",
    "\n",
    "<iframe width=\"560\" height=\"315\"\n",
    "    src=\"https://www.youtube.com/embed/vF7eyJ2g3kU\"\n",
    "    frameborder=\"0\"\n",
    "    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n",
    "    allowfullscreen>\n",
    "</iframe>\n",
    "\n",
    "Positive definite matrices define **quadratic functions with a unique global minimum** — the foundation of optimization and least squares.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Tests for Positive Definiteness (2×2 Case)\n",
    "\n",
    "For symmetric\n",
    "\n",
    "\\[\n",
    "A = \\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "$A$ is **positive definite** $\\iff$\n",
    "\n",
    "- All eigenvalues $> 0$  \n",
    "- $a > 0$ and $\\det(A) = ac - b^2 > 0$  \n",
    "- Both pivots $> 0$: $a > 0$, $\\frac{ac-b^2}{a} > 0$  \n",
    "- $\\boxed{x^T A x > 0 \\quad \\forall x \\neq 0}$\n",
    "\n",
    "**Positive semidefinite**: $x^T A x \\geq 0$ (allows zero eigenvalue, $\\det(A) = 0$).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Examples\n",
    "\n",
    "| Matrix | $x^T A x$ | Classification | Reason |\n",
    "|-------|-----------|----------------|-------|\n",
    "| $\\begin{pmatrix} 2 & 6 \\\\ 6 & 18 \\end{pmatrix}$ | $2x_1^2 + 12x_1 x_2 + 18x_2^2 = 2(x_1 + 3x_2)^2 \\geq 0$ | Semidefinite | $\\det=0$, rank 1 |\n",
    "| $\\begin{pmatrix} 2 & 6 \\\\ 6 & 7 \\end{pmatrix}$ | $2x_1^2 + 12x_1 x_2 + 7x_2^2$ | Indefinite | Saddle (can be negative) |\n",
    "| $\\begin{pmatrix} 2 & 6 \\\\ 6 & 20 \\end{pmatrix}$ | $2x_1^2 + 12x_1 x_2 + 20x_2^2 = 2(x_1 + 3x_2)^2 + 2x_2^2 > 0$ | Definite | Completed square positive |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Completing the Square = Gaussian Elimination\n",
    "\n",
    "For $f(x,y) = ax^2 + 2hxy + cy^2$:\n",
    "\n",
    "\\[\n",
    "f = a\\left(x + \\frac{h}{a}y\\right)^2 + \\left(c - \\frac{h^2}{a}\\right)y^2\n",
    "\\]\n",
    "\n",
    "- First coefficient $a$ → first pivot  \n",
    "- Second coefficient $c - h^2/a$ → second pivot\n",
    "\n",
    "Positive definite $\\iff$ both coefficients $> 0$.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Multivariable Case: Second Derivative Test\n",
    "\n",
    "Consider $f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^T A \\mathbf{x} - \\mathbf{b}^T \\mathbf{x} + c$.\n",
    "\n",
    "Critical point: $\\nabla f = A \\mathbf{x} - \\mathbf{b} = 0 \\quad \\Rightarrow \\quad \\mathbf{x}^* = A^{-1} \\mathbf{b}$ (if $A$ invertible).\n",
    "\n",
    "Second derivative (Hessian): $A$.\n",
    "\n",
    "- $A$ positive definite $\\Rightarrow$ **global minimum** at $\\mathbf{x}^*$.\n",
    "- $A$ indefinite $\\Rightarrow$ saddle.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. 3×3 Tridiagonal Example\n",
    "\n",
    "\\[\n",
    "A = \\begin{pmatrix}\n",
    "2 & -1 & 0 \\\\\n",
    "-1 & 2 & -1 \\\\\n",
    "0 & -1 & 2\n",
    "\\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "Leading minors: $2 > 0$, $\\det\\begin{pmatrix}2 & -1\\\\-1 & 2\\end{pmatrix}=3 > 0$, $\\det(A)=4 > 0$.\n",
    "\n",
    "Pivots (after elimination): $2$, $3/2$, $4/3$ (all positive).\n",
    "\n",
    "Eigenvalues: $2 - \\sqrt{2} \\approx 0.586$, $2$, $2 + \\sqrt{2} \\approx 3.414$ (all positive).\n",
    "\n",
    "Quadratic form contours: **ellipsoids** (not hyperbolas).\n",
    "\n",
    "Axis lengths $\\propto 1/\\sqrt{\\lambda_i}$.\n",
    "\n",
    "---\n",
    "\n",
    "### Code: Visualize Quadratic Forms and Ellipsoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_quadratic_form(A, title):\n",
    "    x = np.linspace(-3, 3, 400)\n",
    "    y = np.linspace(-3, 3, 400)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = A[0,0]*X**2 + 2*A[0,1]*X*Y + A[1,1]*Y**2\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.contourf(X, Y, Z, levels=20, cmap='viridis')\n",
    "    plt.colorbar(label='$$ f(x,y) $$')\n",
    "    plt.contour(X, Y, Z, levels=[0], colors='red', linewidths=2)\n",
    "    plt.xlabel('$$ x $$'); plt.ylabel('$$ y $$')\n",
    "    plt.title(title)\n",
    "    plt.axis('equal')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Positive definite\n",
    "A_pd = np.array([[2, 6], [6, 20]])\n",
    "plot_quadratic_form(A_pd, 'Positive Definite: Elliptical Bowl')\n",
    "\n",
    "# Semidefinite\n",
    "A_psd = np.array([[2, 6], [6, 18]])\n",
    "plot_quadratic_form(A_psd, 'Positive Semidefinite: Trough')\n",
    "\n",
    "# Indefinite\n",
    "A_ind = np.array([[2, 6], [6, 7]])\n",
    "plot_quadratic_form(A_ind, 'Indefinite: Saddle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e6742d",
   "metadata": {},
   "source": [
    "## Lecture 28: Similar matrices and Jordan form\n",
    "\n",
    "<iframe width=\"560\" height=\"315\"\n",
    "    src=\"https://www.youtube.com/embed/TSdXJw83kyA\"\n",
    "    frameborder=\"0\"\n",
    "    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n",
    "    allowfullscreen>\n",
    "</iframe>\n",
    "\n",
    "Not every matrix is diagonalizable, but **every** square matrix is similar to a nearly diagonal **Jordan form** — the cleanest representative of its similarity class.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Similar Matrices\n",
    "\n",
    "Two $n \\times n$ matrices $A$ and $B$ are **similar** if there exists invertible $M$ such that\n",
    "\n",
    "\\[\n",
    "\\boxed{B = M^{-1} A M}\n",
    "\\]\n",
    "\n",
    "Consequences:\n",
    "\n",
    "- Same eigenvalues (characteristic polynomial $\\det(A - \\lambda I) = \\det(B - \\lambda I)$)\n",
    "- Same trace, determinant, rank\n",
    "- Eigenvectors related by $M$: if $A x = \\lambda x$, then $B (M^{-1} x) = \\lambda (M^{-1} x)$\n",
    "\n",
    "Diagonalizable case: $A = M \\Lambda M^{-1}$ → $A$ similar to diagonal $\\Lambda$.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Example: Diagonalizable\n",
    "\n",
    "\\[\n",
    "A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}, \\quad\n",
    "\\Lambda = \\begin{pmatrix} 3 & 0 \\\\ 0 & 1 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "Change-of-basis matrix (easy to invert):\n",
    "\n",
    "\\[\n",
    "M = \\begin{pmatrix} 1 & 4 \\\\ 0 & 1 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "Verify $M^{-1} A M = \\Lambda$ (or equivalently $M^T A M$ in some symmetric cases).\n",
    "\n",
    "All matrices with eigenvalues $3,1$ form a similarity class.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Non-Diagonalizable Case\n",
    "\n",
    "Repeated eigenvalue but insufficient eigenvectors → cannot diagonalize.\n",
    "\n",
    "Example:\n",
    "\n",
    "\\[\n",
    "A = \\begin{pmatrix} 4 & 1 \\\\ 0 & 4 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "Eigenvalues: $4,4$ (trace $8$, det $16$).\n",
    "\n",
    "Only one eigenvector $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ → geometric multiplicity $1 < 2$.\n",
    "\n",
    "Still similar to itself (trivial), but the **Jordan form** reveals the structure.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Jordan Blocks and Jordan Form\n",
    "\n",
    "A **Jordan block** $J_k(\\lambda)$ ($k \\times k$):\n",
    "\n",
    "\\[\n",
    "J_k(\\lambda) = \\begin{pmatrix}\n",
    "\\lambda & 1 & & \\\\\n",
    "& \\lambda & 1 & \\\\\n",
    "& & \\ddots & 1 \\\\\n",
    "& & & \\lambda\n",
    "\\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "**Jordan canonical form theorem**:\n",
    "\n",
    "Every square matrix $A$ is similar to a block-diagonal **Jordan matrix** $J$:\n",
    "\n",
    "\\[\n",
    "\\boxed{A = P J P^{-1}}\n",
    "\\]\n",
    "\n",
    "- Diagonal blocks are Jordan blocks.\n",
    "- Number of blocks for eigenvalue $\\lambda$ = geometric multiplicity (dimension of eigenspace).\n",
    "- Size of largest block = index of eigenvalue.\n",
    "- Diagonalizable $\\iff$ all blocks $1\\times1$ (i.e., $J = \\Lambda$).\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Example: Jordan Form\n",
    "\n",
    "\\[\n",
    "A = \\begin{pmatrix} 4 & 1 \\\\ 0 & 4 \\end{pmatrix} \\quad \\Rightarrow \\quad J = \\begin{pmatrix} 4 & 1 \\\\ 0 & 4 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "(Same as $A$ — already in Jordan form.)\n",
    "\n",
    "Another matrix with same eigenvalues but different structure:\n",
    "\n",
    "\\[\n",
    "\\begin{pmatrix} 5 & 1 \\\\ -1 & 3 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "Trace $8$, det $16$ → same characteristic polynomial → similar.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Zero Eigenvalues Example\n",
    "\n",
    "\\[\n",
    "A = \\begin{pmatrix}\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "Eigenvalues: $0$ (multiplicity $4$).\n",
    "\n",
    "Rank $2$ → nullity $2$ → geometric multiplicity $2$.\n",
    "\n",
    "Jordan form: two blocks (e.g., one $2\\times2$, one $1\\times1$, one $1\\times1$).\n",
    "\n",
    "---\n",
    "\n",
    "### Code: Compute Jordan Form (via Schur or Direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import schur, eig\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Non-diagonalizable example\n",
    "A = np.array([[4, 1],\n",
    "              [0, 4]])\n",
    "\n",
    "# Real Schur form (triangular, close to Jordan for real matrices)\n",
    "T, Z = schur(A, output='real')\n",
    "\n",
    "# Eigenvalues\n",
    "eigvals = eig(A)[0]\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "**Matrix** $$ A = \\\\begin{{pmatrix}} 4 & 1 \\\\\\\\ 0 & 4 \\\\end{{pmatrix}} $$\n",
    "\n",
    "**Eigenvalues**: $$ {np.round(eigvals, 3).tolist()} $$ (repeated)\n",
    "\n",
    "**Real Schur form** $$ T \\\\approx $$ Jordan form:\n",
    "\n",
    "$$  T = \\\\begin{{pmatrix}} {T[0,0]:.3f} & {T[0,1]:.3f} \\\\\\\\ {T[1,0]:.3f} & {T[1,1]:.3f} \\\\end{{pmatrix}}  $$\n",
    "\n",
    "Note the $1$ above diagonal → single $2\\\\times2$ Jordan block for $$ \\\\lambda=4 $$.\n",
    "\n",
    "Geometric multiplicity = $1$ (rank$$ (A-4I)=1 $$).\n",
    "\"\"\"))\n",
    "\n",
    "# Try another matrix\n",
    "A2 = np.array([[5, 1], [-1, 3]])\n",
    "T2, Z2 = schur(A2, output='real')\n",
    "display(Markdown(f\"\"\"\n",
    "**Another similar matrix**:\n",
    "\n",
    "Schur form confirms same Jordan structure.\n",
    "\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "source_map": [
   12,
   149,
   177,
   302,
   335,
   431,
   462,
   599
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}